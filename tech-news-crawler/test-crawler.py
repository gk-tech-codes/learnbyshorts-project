#!/usr/bin/env python3
"""
Test script for the tech news crawler
"""

from crawler import TechNewsCrawler
import json

def main():
    print("ğŸ§ª Testing Tech News Crawler")
    print("============================")
    
    crawler = TechNewsCrawler()
    
    # Test single source first
    source = crawler.config['sources'][0]  # TechCrunch
    print(f"\nğŸ” Testing single source: {source['name']}")
    articles = crawler.crawl_source(source)
    
    if articles:
        print(f"âœ… Successfully crawled {len(articles)} articles")
        print("\nğŸ“° Sample article:")
        print(json.dumps(articles[0], indent=2))
    else:
        print("âŒ No articles found")
    
    # Test full crawl
    print(f"\nğŸš€ Testing full crawl...")
    all_articles = crawler.crawl_all()
    
    if all_articles:
        filename = crawler.save_articles(all_articles)
        print(f"âœ… Full crawl complete! Saved to {filename}")
        
        # Show summary
        sources = {}
        for article in all_articles:
            sources[article['source']] = sources.get(article['source'], 0) + 1
        
        print("\nğŸ“Š Articles by source:")
        for source, count in sources.items():
            print(f"  {source}: {count} articles")
    else:
        print("âŒ Full crawl failed")

if __name__ == "__main__":
    main()
